spring:
  application:
    name: Accounting Management Service
  liquibase:
    enabled: true
    change-log: my/com/maybank/schema/accmgmt/db/changelog/db.changelog-master.yml
  datasource:
    url: ${ACCOUNTING_MANAGEMENT_DATASOURCE_JDBC_URL:jdbc:postgresql://localhost:5432/maybank}
    username: ${ACCOUNTING_MANAGEMENT_DATASOURCE_USERNAME:******}
    password: ${ACCOUNTING_MANAGEMENT_DATASOURCE_PASS:******}
    driver-class-name: ${ACCOUNTING_MANAGEMENT_DATASOURCE_DRIVER_CLASS_NAME:org.postgresql.Driver}
    hikari:
      minimum-idle: ${ACCOUNTING_MANAGEMENT_HIKARI_MINIMUM_IDLE:10}
      maximum-pool-size: ${ACCOUNTING_MANAGEMENT_HIKARI_MAX_POOL_SIZE:250}
      idle-timeout: ${ACCOUNTING_MANAGEMENT_HIKARI_IDLE_TIMEOUT:900000}
  jpa:
    hibernate:
      ddl-auto: none
    show-sql: ${ACCOUNTING_MANAGEMENT_JPA_SHOW_SQL_QUERIES:false}
    open-in-view: ${ACCOUNTING_MANAGEMENT_JPA_OPEN_IN_VIEW:false}
    properties:
      hibernate:
        session:
          events:
            log:
              LOG_QUERIES_SLOWER_THAN_MS: ${ACCOUNTING_MANAGEMENT_JPA_LOG_QUERIES_SLOWER_THAN:250}
        jdbc:
          batch_size: ${ACCOUNTING_MANAGEMENT_JPA_BATCH_SIZE:10}
        order_inserts: true
        order_updates: true
        batch_versioned_data: true
  servlet:
    # https://docs.spring.io/spring-boot/api/java/org/springframework/boot/autoconfigure/web/servlet/MultipartProperties.html
    multipart:
      # max size per-file the upload supports
      max-file-size: ${ACCOUNTING_MANAGEMENT_SERVICE_MULTIPART_MAX_FILE_SIZE:10MB}
      # max size of the whole request
      max-request-size: ${ACCOUNTING_MANAGEMENT_SERVICE_MULTIPART_MAX_REQUEST_SIZE:100MB}

server:
  port: ${ACCOUNTING_MANAGEMENT_REST_SERVICE_PORT:18082}

logging:
  level:
    org.springframework: INFO
    org.springframework.web.reactive.function.client: DEBUG
    reactor.netty.http.client: DEBUG
    my.com.maybank: ${ACCOUNTING_MANAGEMENT_LOGGING_LEVEL:INFO}

app:
  security:
    authn-user:
      # API
      auth-api:
        endpoint: ${ACCOUNTING_MANAGEMENT_AUTH_BASE_ENDPOINT:http://localhost:18081}
        method: POST
        path: /api/v1/user/auth
        authorization: ${ACCOUNTING_MANAGEMENT_AUTH_AUTHZ:******}
        timeunit-timeout: MILLISECONDS
        connect-timeout: 10000
        read-timeout: 10000
  service:
    # data formatting
    data-formatting:
      # date format
      date:
        simple: ${ACCOUNTING_MANAGEMENT_SERVICE_DATAFORMATTING_DATE_SIMPLE:yyyy-MM-dd}
      # time format
      time:
        simple: ${ACCOUNTING_MANAGEMENT_SERVICE_DATAFORMATTING_TIME_SIMPLE:hh:mm:ss}
    # data limiter
    data-limiter:
      # pagination 
      pagination: 
        # maximum hard-defined page-size per-page (this is needed to prevent 
        # attackers to "modify" the page-size to a value that may crash the 
        # server)
        page-size: ${ACCOUNTING_MANAGEMENT_SERVICE_DATALIMITER_PAGINATION_PAGESIZE:50}
    # data paths
    data-path:
      # for upload feature
      upload:
        # destination base path to transfer uploaded file(s)
        dest-base-path: /opt/app/uploads
    # specially for accounting-management-service
    accounting:
      # for kafka feature
      kafka: 
          # POC/demo we had used a kafka container that is preconfigured with 
          # the service endpoint
          endpoint: ${ACCOUNTING_MANAGEMENT_SERVICE_KAFKA_ENDPOINT:localhost:9092}
          # a test topic ; so harcode for demo sake
          topic: ${ACCOUNTING_MANAGEMENT_SERVICE_KAFKA_TOPIC:test}
          # a test group ; so harcode for demo sake
          consumer-group-id: ${ACCOUNTING_MANAGEMENT_SERVICE_KAFKA_CONSUMER_GROUPID:consumer-persist}
          # transaction job batch size (i.e. for each batch the maximum will be 10)
          transaction-job-batch-size: ${ACCOUNTING_MANAGEMENT_JPA_BATCH_SIZE:10}